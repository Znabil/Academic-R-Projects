---
title: "Intelligent Systems. Hands-on 2 (Annotation)"
author: "Aziz nabil"
date: "19/12/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Needed for OutOfMemoryError: Java heap space 
library(rJava)
.jinit(parameters="-Xmx4g")
# If there are more memory problems, invoke gc() after the POS tagging
# The openNLPmodels.en library is not in CRAN; it has to be installed from another repository
#install.packages("openNLPmodels.en", repos = "http://datacube.wu.ac.at")
library(NLP)
library(openNLP) 
library(openNLPmodels.en)
library(tm)
```

### Annotations Functions declaration :

```{r}
#getAnnotationsFromDocument
#getAnnotationsFromDocument returns annotations for the text document: word, sentence, #part-of-speech, and Penn Treebank parse annotations.
getAnnotationsFromDocument = function(doc){
  x=as.String(doc)
  sent_token_annotator <- Maxent_Sent_Token_Annotator()
  word_token_annotator <- Maxent_Word_Token_Annotator()
  pos_tag_annotator <- Maxent_POS_Tag_Annotator()
  y1 <- annotate(x, list(sent_token_annotator, word_token_annotator))
  y2 <- annotate(x, pos_tag_annotator, y1)
  parse_annotator <- Parse_Annotator()
  y3 <- annotate(x, parse_annotator, y2)
  return(y3)  }

#getAnnotatedMergedDocument
#getAnnotatedMergedDocument returns the text document merged with the annotations.
getAnnotatedMergedDocument = function(doc,annotations){
  x=as.String(doc)
  y2w <- subset(annotations, type == "word")
  tags <- sapply(y2w$features, '[[', "POS")
  r1 <- sprintf("%s/%s", x[y2w], tags)
  r2 <- paste(r1, collapse = " ")
  return(r2)  
}
#getAnnotatedPlainTextDocument
#returns the text document along with its annotations in an AnnotatedPlainTextDocument.
getAnnotatedPlainTextDocument = function(doc,annotations){
  x=as.String(doc)
  a = AnnotatedPlainTextDocument(x,annotations)
  return(a)  
} 
```

* Loading corpus data from a local directory

```{r}
source.pos = DirSource("E:\\intelligent systems\\unit_4\\txt_sentoken\\pos", encoding = "UTF-8")
corpus = Corpus(source.pos)
```

* getting the document .
My document id is end with 657 so we gone add 1 to get the right document
```{r}
meta(corpus[[658]])$id
inspect(corpus[[658]])
```

* getting the first 2 sentences of the document and storing them into a new variable .

```{r}
doc=as.String(corpus[658])
sent_token_annotator <- Maxent_Sent_Token_Annotator(language = "en", probs = FALSE, model = NULL)
sentences_ids <-annotate(doc, sent_token_annotator)
sentences <- doc[sentences_ids[1:2]]
sentences

```
### Annotations :
* applying the getAnnotationsFromDocument function to the two sentenses in using lapply.

```{r}
annotations = lapply(sentences, getAnnotationsFromDocument)
```

* The first annotations are sentence annotations. the others are words annotations .

```{r}
head(annotations)
```

* creating AnnotatedPlainTextDocuments that attach the annotations to the document and store the annotated sentences in another variable .
```{r}
sentences.tagged = Map(getAnnotatedPlainTextDocument, sentences, annotations)
sentences.tagged
```
* storing all the annotations inline with the text and store the annotated sentences in another variable .
```{r}
sentences.taggedText = Map(getAnnotatedMergedDocument, sentences, annotations)
sentences.taggedText
```

### Manual evluation of POS
**Manual tagging** : 

+ the/Determiner 1990s/Number produced/Verb two/Number brilliant/Adjective science/Noun fiction/Noun films/Noun .

+ one/Noun was/Verb gattaca/NNP .

**Use the precision and recall metrics :**

Recall = number of correct POS tags in gold data  / number of correct POS tags in tagged data
Precision =  number of correct POS tags in tagged data/ number of total POS tags in tagged data

+ **Precision** = 11/11
+ **Recall**  = 11/11
 